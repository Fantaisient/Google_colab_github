{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyNt275r0wv7"
   },
   "source": [
    "#Marked exercises after Lecture 10 on GANs\n",
    "\n",
    "This notebook contains the marked exercises with instructions and explanations.\n",
    "\n",
    "Work through the cells below in sequential order, executing each cell as you progress. Throughout the exercise, you will encounter instructions marked with the words **YOUR CODE HERE** followed by **raise NotImplementedError()**. You will have to substitute  *raise NotImplementedError()* with your own code.\n",
    "Follow the instructions and write the code to complete the tasks.\n",
    "\n",
    "Along the way, you may also find questions. Try to reflect on the questions before/after running the code.\n",
    "\n",
    "This notebook was developed at the [Idiap Research Institute](https://www.idiap.ch) by [Alina Elena Baia](mailto:alina.baia.idiap.ch>), [Darya Baranouskaya](mailto:darya.baranouskaya.idiap.ch) and [Olena Hrynenko](mailto:olena.hrynenko.idiap.ch) (equal contribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKvAudPzlqc8"
   },
   "source": [
    "Note: This notebook serves as the main file for the marked exercise and contains  the  code for initialising the models, initialising the dataset, setting the hyperparameters for training, and training the model. No code implementation is required in this notebook file. You are allowed to change hyperparameters.\n",
    "\n",
    "Make sure to upload the required source files. You will be asked to modified these files in order to complete the tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You are asked to complete the following tasks related to completing the implementation of a GAN model and its training function, training\n",
    "WGAN [40 points]\n",
    " - 2.10.1 [3 points] Implement DiscriminatorBlock in model.py.\n",
    " - 2.10.2 [5 points] Implement GeneratorBlock in model.py.\n",
    " - 2.10.3 [5 points] Compete Generator in model.py: specify kernel_sizes, stride_sizes, padding_sizes in Generator def __init__.\n",
    " - 2.10.4 [3 points] Implement weight clamping in trainer.py: def clamp_weights(self)\n",
    " - 2.10.5 [9 points] Implement Discriminator update step in trainer.py: def disc_step(self, z, real_images).\n",
    " - 2.10.6 [9 points] Implement Generator update step in trainer.py: def gen_step(self).\n",
    " - 2.10.7 [6 points] Complete the call of disc_step() and gen_step in train_epoch(). Train the GAN for at least 5000 iterations and 5 epochs, and report the generated images.\n",
    "\n",
    "Further instructions and explanations are provided in the accompanying README.md and files.\n",
    "\n",
    "**IMPORTANT REMINDER**: Make sure to also complete the following tasks, which do no require code implementation. Follow the instructions provided in the Marked_exercises_submission2_lecture10.pdf file.\n",
    "\n",
    "\n",
    "Questions [20 points] – Make sure to reference any sources used\n",
    " - 2.10.8 [10 points] Challenges with training GANs (200 words max)\n",
    "Discuss mode collapse as a challenge with training GANs and choose a second challenge yourself. Outline methods that address these challenges. Additionally, state the cause for these challenges. Support your claims with formulas, plots, and graphs. One plot = 50 words.\n",
    "\n",
    " - 2.10.9 [10 points] Evaluation metrics for GANs (200 words max)\n",
    "Discuss two metrics for evaluating the performance of GANs. Describe the advantages and disadvantages of each metric. Support your claims with formulas, plots, and graphs. One plot = 50 words.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-14T11:40:03.932266Z",
     "iopub.status.busy": "2024-05-14T11:40:03.931979Z",
     "iopub.status.idle": "2024-05-14T11:40:03.963325Z",
     "shell.execute_reply": "2024-05-14T11:40:03.962326Z",
     "shell.execute_reply.started": "2024-05-14T11:40:03.932235Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-14T11:40:03.965564Z",
     "iopub.status.busy": "2024-05-14T11:40:03.965293Z",
     "iopub.status.idle": "2024-05-14T11:40:23.270260Z",
     "shell.execute_reply": "2024-05-14T11:40:23.268903Z",
     "shell.execute_reply.started": "2024-05-14T11:40:03.965536Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff4b8f67ab0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from model import Generator, Discriminator, weights_init\n",
    "from trainer import WGANTrainer\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "####Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-14T12:23:17.680494Z",
     "iopub.status.busy": "2024-05-14T12:23:17.679747Z",
     "iopub.status.idle": "2024-05-14T12:23:18.139788Z",
     "shell.execute_reply": "2024-05-14T12:23:18.138385Z",
     "shell.execute_reply.started": "2024-05-14T12:23:17.680437Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_fashion_mnist_dataset(batch_size):\n",
    "    transforms_fashion_mnist = transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    ])\n",
    "    dataset = datasets.FashionMNIST(root='./data', train=True, download=True,\n",
    "                                     transform=transforms_fashion_mnist)\n",
    "    # For testing your implementation we recommend to use a subset of the dataset to save images more often,\n",
    "    # although that would be reflected in the quality of the generated images\n",
    "    from torch.utils.data import Subset\n",
    "    dataset = Subset(dataset, range(40000))\n",
    "    # dataset = Subset(dataset, range(880)) # TEST\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "####Set the hyperparameters and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-14T12:23:18.465806Z",
     "iopub.status.busy": "2024-05-14T12:23:18.464153Z",
     "iopub.status.idle": "2024-05-14T12:23:44.369373Z",
     "shell.execute_reply": "2024-05-14T12:23:44.367355Z",
     "shell.execute_reply.started": "2024-05-14T12:23:18.465742Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (layers): Sequential(\n",
      "    (0): GeneratorBlock(\n",
      "      (deconv_block): Sequential(\n",
      "        (0): ConvTranspose2d(100, 1024, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): GeneratorBlock(\n",
      "      (deconv_block): Sequential(\n",
      "        (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): GeneratorBlock(\n",
      "      (deconv_block): Sequential(\n",
      "        (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): GeneratorBlock(\n",
      "      (deconv_block): Sequential(\n",
      "        (0): ConvTranspose2d(256, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (tanh): Tanh()\n",
      ")\n",
      "Discriminator(\n",
      "  (layers): Sequential(\n",
      "    (0): DiscriminatorBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(1, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): DiscriminatorBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): DiscriminatorBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "        (1): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (cls): DiscriminatorBlock(\n",
      "    (conv_block): Sequential(\n",
      "      (0): Conv2d(1024, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:20, 20.92s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 41\u001b[0m\n\u001b[1;32m     36\u001b[0m trainer \u001b[38;5;241m=\u001b[39m WGANTrainer(model_gen\u001b[38;5;241m=\u001b[39mgen, model_disc\u001b[38;5;241m=\u001b[39mdisc,\n\u001b[1;32m     37\u001b[0m                         optimizer_gen\u001b[38;5;241m=\u001b[39moptimizer_gen, optimizer_disc\u001b[38;5;241m=\u001b[39moptimizer_disc,\n\u001b[1;32m     38\u001b[0m                         n_disc_steps\u001b[38;5;241m=\u001b[39mn_critic_steps, weight_cliping\u001b[38;5;241m=\u001b[39mweight_cliping_limit, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#train WGAN\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# trainer.train(n_epoches=1, train_loader=train_loader) # test\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# trainer.train(n_epoches=30, train_loader=train_loader) # original\u001b[39;00m\n",
      "File \u001b[0;32m~/Documentation/DeepL_marked5/trainer.py:263\u001b[0m, in \u001b[0;36mWGANTrainer.train\u001b[0;34m(self, n_epoches, train_loader)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_gen\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_disc\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 263\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# save the current weights of the models in 'generator.pt' and 'discriminator.pt' files\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_models(epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documentation/DeepL_marked5/trainer.py:234\u001b[0m, in \u001b[0;36mWGANTrainer.train_epoch\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    230\u001b[0m z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((real_images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# print(\"Working on batch number : \", batch_num+1, \"/\", len(train_loader)) # JUST FOR ME RN\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# pass the correct attributed into the disc_step\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisc_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m### BEGIN SOLUTION\u001b[39;49;00m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreal_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# SHOULDNT NOISE Z BE GAUSSIAN = RANDN INSTEAD OF RAND ?\u001b[39;49;00m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m### END SOLUTION\u001b[39;49;00m\n\u001b[1;32m    239\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# optimization generator every n_disc_steps\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_num \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_disc_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m# print(\"Also optimize on generator this time as batch number is pair\") # JUST FOR ME RN\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# this should speed up the training, so that redundunt gradients are not computed\u001b[39;00m\n",
      "File \u001b[0;32m~/Documentation/DeepL_marked5/trainer.py:215\u001b[0m, in \u001b[0;36mWGANTrainer.disc_step\u001b[0;34m(self, real_images, noise)\u001b[0m\n\u001b[1;32m    212\u001b[0m loss_disc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(critic_fake_output) \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(critic_real_output)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# 3\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m \u001b[43mloss_disc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# need to ensure to update of weights of gen ? je me dem si pas déjà fait dans train_epoch qd il fait require_grad\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_disc\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclamp_weights()\n",
      "File \u001b[0;32m/opt/jlab-env/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jlab-env/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# You are allowed to change hyperparameters\n",
    "# Although, if you implemented everything correctly this hyperparmeters should work\n",
    "lr_gen = 0.00007\n",
    "lr_disc = 0.00005\n",
    "#batch_size = 64 # original\n",
    "batch_size = 8\n",
    "weight_cliping_limit = 0.01\n",
    "n_critic_steps = 2\n",
    "n_image_channels = 1  #3 if RGB and 1 if Greyscale\n",
    "\n",
    "gen = Generator(in_channels=100, out_channels=n_image_channels)\n",
    "disc = Discriminator(in_channels=n_image_channels)\n",
    "\n",
    "print(gen.apply(weights_init))\n",
    "print(disc.apply(weights_init))\n",
    "\n",
    "gen.to(device)\n",
    "disc.to(device)\n",
    "\n",
    "# assert for you to check the correctness of the sizes of models outputs\n",
    "z = torch.rand((4, 100, 1, 1), device=device)\n",
    "fake_image = gen(z)\n",
    "assert list(fake_image.shape) == [4, n_image_channels, 32, 32]\n",
    "assert list(disc(fake_image).shape) == [4, 1, 1, 1]\n",
    "\n",
    "\n",
    "# WGAN with gradient clipping uses RMSprop instead of ADAM\n",
    "optimizer_gen = torch.optim.RMSprop(gen.parameters(), lr=lr_gen)\n",
    "optimizer_disc = torch.optim.RMSprop(disc.parameters(), lr=lr_disc)\n",
    "\n",
    "train_loader = load_fashion_mnist_dataset(batch_size)\n",
    "\n",
    "#initialise the trainer\n",
    "trainer = WGANTrainer(model_gen=gen, model_disc=disc,\n",
    "                        optimizer_gen=optimizer_gen, optimizer_disc=optimizer_disc,\n",
    "                        n_disc_steps=n_critic_steps, weight_cliping=weight_cliping_limit, device=device)\n",
    "\n",
    "#train WGAN\n",
    "trainer.train(n_epoches=5, train_loader=train_loader)\n",
    "# trainer.train(n_epoches=1, train_loader=train_loader) # test\n",
    "# trainer.train(n_epoches=30, train_loader=train_loader) # original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T12:10:45.815017Z",
     "iopub.status.busy": "2024-05-14T12:10:45.814660Z",
     "iopub.status.idle": "2024-05-14T12:10:46.041664Z",
     "shell.execute_reply": "2024-05-14T12:10:46.040348Z",
     "shell.execute_reply.started": "2024-05-14T12:10:45.814987Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "MyKernelDeepL",
   "language": "python",
   "name": "mykerneldeepl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
